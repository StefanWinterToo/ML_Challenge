{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "import tensorflow as tf\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model: NN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from keras.optimizers import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#evaluation metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "#test_file.files #test how to find the zipped files and call them\n",
    "train_file  = np.load(\"data/train_data_label.npz\")\n",
    "X           = train_file[\"train_data\"]\n",
    "y           = train_file[\"train_label\"]\n",
    "\n",
    "test_file   = np.load(\"data/test_data_label.npz\")\n",
    "X_test       = test_file[\"test_data\"]\n",
    "y_test       = test_file[\"test_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784)\n",
      "(27455,)\n",
      "(7172, 784)\n",
      "(7172,)\n",
      "(18303, 784)\n",
      "(18303,)\n",
      "(9152, 784)\n",
      "(9152,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-score features \n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess y with onehot encoding\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(18303, 784)\n",
      "(18303, 24)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(Y_train[0])\n",
    "print(Y_val[0])\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "572/572 [==============================] - 7s 11ms/step - loss: 0.7868 - accuracy: 0.8095\n",
      "Epoch 2/4\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 0.1276 - accuracy: 0.9919\n",
      "Epoch 3/4\n",
      "572/572 [==============================] - 8s 13ms/step - loss: 0.0396 - accuracy: 0.9998\n",
      "Epoch 4/4\n",
      "572/572 [==============================] - 8s 13ms/step - loss: 0.0180 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x295240b8188>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run model on train data, without pca and gridsearch\n",
    "optimizers = Adam(lr = 0.0001)\n",
    "ann = models.Sequential([\n",
    "    layers.Dense(x_dim, input_dim=x_dim, activation='tanh'),\n",
    "    layers.Dense(x_dim, activation='tanh'),\n",
    "    layers.Dense(y_dim, activation='softmax')    \n",
    "])\n",
    "ann.compile(optimizer=optimizers, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ann.fit(X_train, Y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2863915225878416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       331\n",
      "           1       0.96      0.50      0.66       432\n",
      "           2       0.93      0.68      0.78       310\n",
      "           3       0.63      0.53      0.58       245\n",
      "           4       0.80      0.87      0.83       498\n",
      "           5       0.42      0.90      0.57       247\n",
      "           6       0.95      0.22      0.36       348\n",
      "           7       0.71      0.67      0.69       436\n",
      "           8       0.37      0.32      0.34       288\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00       331\n",
      "          11       0.00      0.00      0.00       209\n",
      "          12       0.28      0.05      0.08       394\n",
      "          13       0.00      0.00      0.00       291\n",
      "          14       0.00      0.00      0.00       246\n",
      "          15       0.00      0.00      0.00       347\n",
      "          16       0.00      0.00      0.00       164\n",
      "          17       0.00      0.00      0.00       144\n",
      "          18       0.00      0.00      0.00       246\n",
      "          19       0.04      0.08      0.05       248\n",
      "          20       0.00      0.00      0.00       266\n",
      "          21       0.11      0.08      0.09       346\n",
      "          22       0.00      0.00      0.00       206\n",
      "          23       0.00      0.00      0.00       267\n",
      "          24       0.00      0.00      0.00       332\n",
      "\n",
      "    accuracy                           0.29      7172\n",
      "   macro avg       0.28      0.23      0.24      7172\n",
      "weighted avg       0.35      0.29      0.29      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run model on test data\n",
    "y_pred = ann.predict_classes(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize right embedding parameters\n",
    "x_dim = X_train.shape[1]\n",
    "x_dim_pca = X_train_pca.shape[1]\n",
    "y_dim = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on train data with 784 features without PCA\n",
    "def nn(optimizer='rmsprop'):\n",
    "    ann = models.Sequential([\n",
    "        layers.Dense(x_dim, input_dim=x_dim, activation='tanh'),\n",
    "        layers.Dense(x_dim, activation='tanh'),\n",
    "        layers.Dense(y_dim, activation='softmax')    \n",
    "    ])\n",
    "    ann.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=nn, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter space\n",
    "epochs     = [5,10]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, cv=3, param_grid=hyperparameters)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986 - {'epochs': 5, 'optimizer': 'rmsprop'}\n",
      "0.993 - {'epochs': 5, 'optimizer': 'adam'}\n",
      "0.997 - {'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "1.0   - {'epochs': 10, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#for i in range(len(CV.cv_results_[\"mean_test_score\"])):\n",
    "for i in range(len(grid.cv_results_[\"mean_test_score\"])):\n",
    "    print(\"{:<5} - {}\".format(np.round(grid.cv_results_[\"mean_test_score\"][i],3), grid.cv_results_[\"params\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       331\n",
      "           1       0.63      0.82      0.71       432\n",
      "           2       1.00      0.82      0.90       310\n",
      "           3       0.51      0.91      0.65       245\n",
      "           4       0.83      0.71      0.77       498\n",
      "           5       0.51      0.79      0.62       247\n",
      "           6       0.67      0.37      0.48       348\n",
      "           7       0.76      0.54      0.63       436\n",
      "           8       0.47      0.51      0.49       288\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00       331\n",
      "          11       0.00      0.00      0.00       209\n",
      "          12       0.21      0.03      0.05       394\n",
      "          13       0.00      0.00      0.00       291\n",
      "          14       0.00      0.00      0.00       246\n",
      "          15       0.00      0.00      0.00       347\n",
      "          16       0.00      0.00      0.00       164\n",
      "          17       0.00      0.00      0.00       144\n",
      "          18       0.00      0.00      0.00       246\n",
      "          19       0.04      0.06      0.05       248\n",
      "          20       0.00      0.00      0.00       266\n",
      "          21       0.06      0.02      0.03       346\n",
      "          22       0.00      0.00      0.00       206\n",
      "          23       0.00      0.01      0.01       267\n",
      "          24       0.00      0.00      0.00       332\n",
      "\n",
      "    accuracy                           0.31      7172\n",
      "   macro avg       0.26      0.26      0.25      7172\n",
      "weighted avg       0.32      0.31      0.30      7172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Gebruiker\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize pca to reduce features\n",
    "pca = PCA(0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on train data with 34 features from PCA\n",
    "def nn(optimizer='rmsprop'):\n",
    "    ann = models.Sequential([\n",
    "        layers.Dense(x_dim_pca, input_dim=x_dim_pca, activation='tanh'),\n",
    "        layers.Dense(x_dim_pca, activation='tanh'),\n",
    "        layers.Dense(y_dim, activation='softmax')    \n",
    "    ])\n",
    "    ann.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=nn, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter space\n",
    "epochs     = [5,10]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, cv=3, param_grid=hyperparameters)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(X_train_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(CV.cv_results_[\"mean_test_score\"])):\n",
    "for i in range(len(grid.cv_results_[\"mean_test_score\"])):\n",
    "    print(\"{:<5} - {}\".format(np.round(grid.cv_results_[\"mean_test_score\"][i],3), grid.cv_results_[\"params\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_result.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
